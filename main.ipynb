{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/kevin/mlruns/998316277040792967', creation_time=1707907843550, experiment_id='998316277040792967', last_update_time=1707907843550, lifecycle_stage='active', name='moviewise', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from hidden import MONGO_USR, MONGO_PWD\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Connexion à la base de données\n",
    "client = MongoClient('mongodb://'+ MONGO_USR +':'+ MONGO_PWD +'@127.0.0.1:27017/?authSource=admin')\n",
    "# client = MongoClient('127.0.0.1:27017', username= \"MONGO_USR\", password= \"MONGO_PWD\")\n",
    "db = client['Movielens']\n",
    "movies = db['movies']\n",
    "users = db['users']\n",
    "\n",
    "# Identification de l'interface MLflow\n",
    "mlflow.set_tracking_uri(\"file://\" + os.path.expanduser('~/mlruns'))\n",
    "# Identification du nom du projet MLflow\n",
    "mlflow.set_experiment(\"moviewise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.DataFrame(movies.find({}, {\"_id\": 1, \"title\": 1}))\n",
    "\n",
    "# Récupérer les données de la base de données\n",
    "data = list(users.find({}, {\"movies.movieid\": 1, \"_id\": 1, \"movies.rating\": 1, \"movies.timestamp\": 1}))\n",
    "\n",
    "# Convertir les données en DataFrame\n",
    "users = pd.json_normalize(data)\n",
    "\n",
    "# \"Dérouler\" la liste movies\n",
    "users = users.explode('movies')\n",
    "\n",
    "# Convertir chaque élément de la liste en une colonne distincte\n",
    "users_tmp = users['movies'].apply(pd.Series)\n",
    "users = pd.concat([users, users_tmp], axis=1).drop('movies', axis=1)\n",
    "\n",
    "print('taille de movies :', len(movies))\n",
    "print('taille de users :', len(users))\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = movies.merge(users, left_on='_id', right_on='movieid')\n",
    "\n",
    "# drop \"movieid\" column\n",
    "merged_df = merged_df.drop(columns=['movieid'])\n",
    "\n",
    "# rename \"_id_x\" column to \"movieid\"\n",
    "merged_df = merged_df.rename(columns={\"_id_x\": \"movieid\"})\n",
    "\n",
    "# rename \"_id_y\" column to \"user_id\"\n",
    "merged_df = merged_df.rename(columns={\"_id_y\": \"user_id\"})\n",
    "\n",
    "# Sort merged_df by timestamp\n",
    "merged_df = merged_df.sort_values(by=['timestamp'])\n",
    "\n",
    "# Reset index\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "# Drop the first entire line because of the odd size of the dataset\n",
    "merged_df = merged_df.drop(merged_df.index[0])\n",
    "\n",
    "print('Taille de merged_df :', len(merged_df))\n",
    "merged_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ratings per movie\n",
    "movies_counts = merged_df['movieid'].value_counts()\n",
    "print(movies_counts.describe())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Number of ratings per user\n",
    "cusers_counts = merged_df['user_id'].value_counts()\n",
    "print(cusers_counts.describe())\n",
    "\n",
    "# Define the thresholds under which we drop the movies\n",
    "movies_threshold = 33\n",
    "users_threshold = 44\n",
    "\n",
    "# Drop movies with less than 33 ratings\n",
    "merged_df = merged_df[merged_df['movieid'].isin(movies_counts[movies_counts > movies_threshold].index)]\n",
    "\n",
    "# Drop users with less than 44 ratings\n",
    "merged_df = merged_df[merged_df['user_id'].isin(cusers_counts[cusers_counts > users_threshold].index)]\n",
    "\n",
    "print('\\n')\n",
    "print('Nouvelle taille de merged_df :', len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split merged_df into train (80%) and test (20%) dataframes\n",
    "train_size = int(0.8 * len(merged_df))\n",
    "df_train = merged_df[:train_size]\n",
    "df_test = merged_df[train_size:]\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop every line of df_test that contains a movieid that is not in df_train\n",
    "films_df_train = df_train['movieid'].unique()\n",
    "df_test = df_test[df_test['movieid'].isin(films_df_train)]\n",
    "\n",
    "# Drop every line of df_test that contains a user_id that is not in df_train\n",
    "users_df_train = df_train['user_id'].unique()\n",
    "df_test = df_test[df_test['user_id'].isin(users_df_train)]\n",
    "\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot train dataframe to get a matrix of users and their ratings for movies\n",
    "ratings_train = df_train.pivot(index='user_id', columns='movieid', values='rating')\n",
    "\n",
    "ratings_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with \n",
    "ratings_train = ratings_train.fillna(0)\n",
    "\n",
    "# Drop lines with only zeros\n",
    "ratings_train = ratings_train[ratings_train.sum(axis=1) > 0]\n",
    "\n",
    "# Sparse ratings train dataframe\n",
    "ratings_train_sparse = ratings_train.astype(pd.SparseDtype(\"float\", 0))\n",
    "\n",
    "ratings_train_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "max_iter = 100\n",
    "nmf = NMF(n_components=n_components, max_iter=max_iter)\n",
    "\n",
    "# Fit the model to the user-item train matrix\n",
    "U_train = nmf.fit_transform(ratings_train_sparse)  # User matrix train\n",
    "M = nmf.components_  # Item matrix\n",
    "\n",
    "pred_matrix = np.dot(U_train, M)\n",
    "pred_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"unpivot\" the matrix returned to get\n",
    "pred_df = pd.DataFrame(pred_matrix, columns=ratings_train.columns, index=ratings_train.index)\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the dataframe\n",
    "pred_df = pred_df.stack().reset_index()\n",
    "pred_df.columns = ['user_id', 'movieid', 'user_movie_position'] # Rename columns\n",
    "\n",
    "# Merge the train and test dataframes with the predictions dataframe\n",
    "train_pred_df = pd.merge(df_train, pred_df, on=['user_id', 'movieid'])\n",
    "test_pred_df = pd.merge(df_test, pred_df, on=['user_id', 'movieid'])\n",
    "\n",
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE\n",
    "mse_train = mean_squared_error(train_pred_df['rating'], train_pred_df['user_movie_position'])\n",
    "mse_test = mean_squared_error(test_pred_df['rating'], test_pred_df['user_movie_position'])\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.log_model(nmf, \"Model\")\n",
    "    mlflow.log_params({\"n_components\": n_components})\n",
    "    mlflow.log_metric(\"Training MSE\", mse_train)\n",
    "    mlflow.log_metric(\"Test MSE\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort test_pred_df by user_movie_position for every user ans reset index\n",
    "test_pred_df = test_pred_df.sort_values(by=['user_id', 'user_movie_position'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# Create a dataframe with the top 10 ratings for each user\n",
    "top_10_df = test_pred_df.groupby('user_id').head(10)\n",
    "\n",
    "# Pour chaque groupe, calculer le coefficient de corrélation de Spearman et l'ajouter au dataframe des résultats\n",
    "grouped = top_10_df.groupby('user_id')\n",
    "results = pd.DataFrame(columns=['user_id', 'spearman_corr'])\n",
    "for user, group in grouped:\n",
    "    spearman_corr = group['rating'].corr(group['user_movie_position'], method='spearman')\n",
    "    results.loc[len(results)] = [user, spearman_corr]\n",
    "\n",
    "# Afficher les résultats\n",
    "results.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regarder les meilleurs notes pourchaque user (parmis les films qu'il a déjà regarder) et regarder leurs positions dans la matrice de prédiction.\n",
    "# OU Faire un top 10 des films pour chaque user et calculer la moyenne de ces notes (à mettre dans un dataframe à log dans MLflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
